{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0645805f-3872-47ad-bc06-6e413792c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting file at: C:\\Users\\shanp\\fake_data_energy.csv\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "# CELL 1\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import difflib\n",
    "import traceback\n",
    "\n",
    "# Define your file path (you told me both notebook and file are in C:\\Users\\shanp)\n",
    "file_path = r\"C:\\Users\\shanp\\Original Data to Fake format Fill RP.xlsx\"\n",
    "print(\"Expecting file at:\", file_path)\n",
    "print(\"Exists:\", os.path.exists(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9decb2-9e8a-46e4-81c6-3edf6b63583d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(file_path):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExcel file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please ensure the file is exactly at that path.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m xls = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSheets in workbook:\u001b[39m\u001b[33m\"\u001b[39m, xls.sheet_names)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# We'll try to load a sheet matching the string you gave; if that fails, we'll use the first sheet.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\sisepuede\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1554\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1550\u001b[39m     ext = inspect_excel_format(\n\u001b[32m   1551\u001b[39m         content_or_path=path_or_buffer, storage_options=storage_options\n\u001b[32m   1552\u001b[39m     )\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n\u001b[32m   1559\u001b[39m engine = config.get_option(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.reader\u001b[39m\u001b[33m\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    "# CELL 2\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Excel file not found at {file_path}. Please ensure the file is exactly at that path.\")\n",
    "\n",
    "xls = pd.ExcelFile(file_path)\n",
    "print(\"Sheets in workbook:\", xls.sheet_names)\n",
    "\n",
    "# We'll try to load a sheet matching the string you gave; if that fails, we'll use the first sheet.\n",
    "preferred_sheet = \"Original Data to Fake format Fill RP.xlsx\"  # you gave this earlier; we'll attempt it but fallback to first sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b38f72-ca52-4701-903b-b8dfe700fad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 3\n",
    "try:\n",
    "    # Try loading the sheet by exact name first (in case that's actually the sheet name)\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=preferred_sheet)\n",
    "    used_sheet = preferred_sheet\n",
    "    print(f\"Loaded sheet by name: {used_sheet}\")\n",
    "except Exception as e:\n",
    "    # Fallback to first sheet\n",
    "    df_raw = pd.read_excel(file_path, sheet_name=0)\n",
    "    used_sheet = xls.sheet_names[0]\n",
    "    print(f\"Could not load by name ({preferred_sheet}). Fallback to first sheet: {used_sheet}\")\n",
    "\n",
    "print(\"Raw data shape:\", df_raw.shape)\n",
    "display(df_raw.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c6a37-530b-421e-aa19-f0c39b552ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 4\n",
    "print(\"Columns (first 80 shown):\")\n",
    "for i, c in enumerate(df_raw.columns[:80], start=1):\n",
    "    print(f\"{i}. {c}\")\n",
    "\n",
    "print(\"\\nColumn dtypes (first 40):\")\n",
    "print(df_raw.dtypes.head(40))\n",
    "\n",
    "print(\"\\nTop null counts:\")\n",
    "print(df_raw.isnull().sum().sort_values(ascending=False).head(40))\n",
    "\n",
    "# summary table for convenience\n",
    "summary = pd.DataFrame({\n",
    "    \"dtype\": df_raw.dtypes.astype(str),\n",
    "    \"null_count\": df_raw.isnull().sum(),\n",
    "    \"n_unique\": df_raw.nunique(dropna=False)\n",
    "}).sort_values(by=\"null_count\", ascending=False)\n",
    "display(summary.head(80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aff95-6e5d-4589-b205-4b2c3c8f7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5\n",
    "# Attempt to import sisepuede examples to get the expected column schema.\n",
    "example_loaded = False\n",
    "example_cols = []\n",
    "try:\n",
    "    from sisepuede.manager.sisepuede_examples import SISEPUEDEExamples\n",
    "    examples = SISEPUEDEExamples()\n",
    "    df_example = examples(\"input_data_frame\")\n",
    "    example_cols = list(df_example.columns)\n",
    "    example_loaded = True\n",
    "    print(\"Loaded SISEPUEDE example input shape:\", df_example.shape)\n",
    "    print(\"Example columns (first 60):\", example_cols[:60])\n",
    "except Exception as e:\n",
    "    print(\"Could NOT load SISEPUEDE example automatically. That's ok — we'll proceed with data prep.\")\n",
    "    print(\"Error (truncated):\", str(e)[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95131a2-7c0a-4a97-b640-2e0dde2d0e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 6\n",
    "my_cols = list(df_raw.columns)\n",
    "mapping_suggestion = {}\n",
    "if example_loaded and example_cols:\n",
    "    for ex in example_cols:\n",
    "        matches = difflib.get_close_matches(ex, my_cols, n=1, cutoff=0.45)\n",
    "        if matches:\n",
    "            mapping_suggestion[matches[0]] = ex\n",
    "\n",
    "    print(\"Auto mapping suggestions (your_col -> example_col):\")\n",
    "    for your_col, ex_col in mapping_suggestion.items():\n",
    "        print(f\"'{your_col}'  ->  '{ex_col}'\")\n",
    "else:\n",
    "    print(\"No example columns available for mapping suggestions. You will need to map manually if required.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959decb7-ae53-45c0-a841-cd76bf7f490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7\n",
    "df_mapped = df_raw.copy()\n",
    "\n",
    "# Apply the automatic mapping if we produced suggestions\n",
    "if mapping_suggestion:\n",
    "    rename_dict = {your_col: ex_col for your_col, ex_col in mapping_suggestion.items()}\n",
    "    df_mapped = df_mapped.rename(columns=rename_dict)\n",
    "    print(f\"Applied {len(rename_dict)} automatic renames.\")\n",
    "else:\n",
    "    print(\"No automatic renames applied. You can rename manually with df_mapped.rename(columns={...}, inplace=True).\")\n",
    "\n",
    "# Ensure minimal required columns exist for SISEPUEDE workflows: 'region' and 'time_period'\n",
    "if 'region' not in df_mapped.columns:\n",
    "    print(\"`region` missing — adding default 'costa_rica'.\")\n",
    "    df_mapped['region'] = 'costa_rica'\n",
    "\n",
    "# Try to detect a year/time column for time_period; otherwise default to 2015\n",
    "if 'time_period' not in df_mapped.columns:\n",
    "    candidate_year_cols = [c for c in df_mapped.columns if c.lower() in ('year','years','time','time_period','period')]\n",
    "    if candidate_year_cols:\n",
    "        chosen = candidate_year_cols[0]\n",
    "        print(\"Found a candidate year column:\", chosen, \"— copying to time_period (coerced to int).\")\n",
    "        df_mapped['time_period'] = pd.to_numeric(df_mapped[chosen], errors='coerce').fillna(2015).astype(int)\n",
    "    else:\n",
    "        print(\"No year-like column found. Creating time_period with default 2015.\")\n",
    "        df_mapped['time_period'] = 2015\n",
    "\n",
    "# Ensure time_period int\n",
    "try:\n",
    "    df_mapped['time_period'] = df_mapped['time_period'].astype(int)\n",
    "except Exception:\n",
    "    df_mapped['time_period'] = pd.to_numeric(df_mapped['time_period'], errors='coerce').fillna(2015).astype(int)\n",
    "\n",
    "print(\"df_mapped shape:\", df_mapped.shape)\n",
    "display(df_mapped.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f93f6f-be3f-420f-afb7-3cf7c7e7adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8\n",
    "if example_loaded:\n",
    "    example_set = set(example_cols)\n",
    "    my_set = set(df_mapped.columns)\n",
    "    missing = sorted(example_set - my_set)\n",
    "    extra = sorted(my_set - example_set)\n",
    "    print(f\"Missing columns (count {len(missing)}). Showing up to 80:\")\n",
    "    print(missing[:80])\n",
    "    print(f\"\\nExtra columns in your data (count {len(extra)}). Showing up to 80:\")\n",
    "    print(extra[:80])\n",
    "else:\n",
    "    print(\"Example not loaded — skip comparison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8c2b8-9125-4e4c-ac4d-3d24744582d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9\n",
    "out_csv = r\"C:\\Users\\shanp\\df_input_for_sisepuede.csv\"\n",
    "df_mapped.to_csv(out_csv, index=False)\n",
    "print(\"Saved cleaned df_mapped to:\", out_csv)\n",
    "\n",
    "# Use df_input variable used by your pipeline\n",
    "df_input = df_mapped.copy()\n",
    "print(\"Prepared df_input shape:\", df_input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffc58e-0498-49d7-b137-a04df7525602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 10\n",
    "try:\n",
    "    import sisepuede as si\n",
    "    import sisepuede.transformers as trf\n",
    "    print(\"Imported sisepuede successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Could not import sisepuede in this environment. If sisepuede is installed, ensure the kernel has it. Error:\")\n",
    "    print(str(e))\n",
    "    trf = None\n",
    "    si = None\n",
    "\n",
    "if trf is not None:\n",
    "    try:\n",
    "        transformers = trf.Transformers({}, df_input=df_input)\n",
    "        print(\"Transformers object created. Count:\", len(transformers.all_transformers))\n",
    "    except Exception as e:\n",
    "        print(\"Error creating Transformers object:\")\n",
    "        traceback.print_exc()\n",
    "        transformers = None\n",
    "\n",
    "    # Try running a couple of common transformers (skip missing)\n",
    "    if transformers is not None:\n",
    "        test_codes = [\"TFR:TRNS:SHIFT_FUEL_MEDIUM_DUTY\", \"TFR:ENTC:TARGET_RENEWABLE_ELEC\"]\n",
    "        for code in test_codes:\n",
    "            try:\n",
    "                transformer = transformers.get_transformer(code)\n",
    "                print(f\"Running transformer: {code}\")\n",
    "                df_transformed = transformer()\n",
    "                print(f\"Transformer {code} produced shape:\", df_transformed.shape)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not run transformer {code}. Error:\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "    # Try initializing a dummy SISEPUEDE model (no Julia)\n",
    "    try:\n",
    "        ssp = si.SISEPUEDE(\n",
    "            \"calibrated\",\n",
    "            id_str=\"test_run\",\n",
    "            initialize_as_dummy=True,\n",
    "            regions=list(df_input['region'].unique())\n",
    "        )\n",
    "        print(\"Dummy SISEPUEDE model initialized. Strategies available:\", len(ssp.attribute_strategy.table))\n",
    "    except Exception:\n",
    "        print(\"Failed to initialize SISEPUEDE model (dummy). Traceback:\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Skipping transformer steps since sisepuede import was not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741dec6-4f40-4eca-86d1-e7f7a082aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11\n",
    "numeric_cols = df_input.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "print(\"Numeric columns sample:\", numeric_cols[:30])\n",
    "\n",
    "if numeric_cols:\n",
    "    sample_var = numeric_cols[0]\n",
    "    print(\"Plotting sample:\", sample_var)\n",
    "    ax = df_input.groupby('time_period')[sample_var].sum().plot(title=f\"Total {sample_var} by time_period\", figsize=(10,4))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric columns to plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64200ef-4baf-4633-9b39-f162d724a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12.5: Install seaborn\n",
    "!pip install seaborn\n",
    "\n",
    "print(\"✓ Seaborn installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9abfe-8604-4253-af77-cbce0cec59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 13: Setup for Advanced Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Visualization libraries ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31467e-cd98-437b-b852-4a1528f8e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 14: Identify Emission and Economic Columns\n",
    "# Find all emission-related columns\n",
    "emission_cols = [col for col in df_input.columns if 'emission' in col.lower() or 'co2' in col.lower()]\n",
    "print(f\"Found {len(emission_cols)} emission columns\")\n",
    "print(\"Sample emission columns:\", emission_cols[:10])\n",
    "\n",
    "# Find GDP/economic columns\n",
    "gdp_cols = [col for col in df_input.columns if 'gdp' in col.lower() or 'economic' in col.lower() or 'value_added' in col.lower()]\n",
    "print(f\"\\nFound {len(gdp_cols)} GDP/economic columns\")\n",
    "print(\"Sample GDP columns:\", gdp_cols[:10])\n",
    "\n",
    "# Find sector-specific columns\n",
    "sector_keywords = ['agrc', 'energy', 'transport', 'waste', 'industry', 'ippu', 'afolu']\n",
    "sector_cols = {}\n",
    "for keyword in sector_keywords:\n",
    "    cols = [col for col in df_input.columns if keyword in col.lower()]\n",
    "    if cols:\n",
    "        sector_cols[keyword] = cols\n",
    "        print(f\"\\n{keyword.upper()}: {len(cols)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09182522-3abb-4bcc-8d72-1ab14f5ede87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 15: Calculate Total Emissions by Time Period\n",
    "# Aggregate all emission columns by time period\n",
    "if emission_cols:\n",
    "    # Select numeric emission columns only\n",
    "    valid_emission_cols = []\n",
    "    for col in emission_cols:\n",
    "        try:\n",
    "            if pd.api.types.is_numeric_dtype(df_input[col]):\n",
    "                valid_emission_cols.append(col)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"Using {len(valid_emission_cols)} valid numeric emission columns\")\n",
    "    \n",
    "    if valid_emission_cols:\n",
    "        # Calculate total emissions per time period\n",
    "        df_emissions = df_input.groupby('time_period')[valid_emission_cols].sum()\n",
    "        df_emissions['total_emissions'] = df_emissions.sum(axis=1)\n",
    "        \n",
    "        print(\"\\nEmissions summary:\")\n",
    "        display(df_emissions[['total_emissions']].head(10))\n",
    "    else:\n",
    "        print(\"No valid numeric emission columns found\")\n",
    "        df_emissions = None\n",
    "else:\n",
    "    print(\"No emission columns found in dataset\")\n",
    "    df_emissions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd09fc-f9fe-441a-b00c-5fb0de20b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 16: Create Stacked Area Chart (Like Your Screenshot)\n",
    "if df_emissions is not None and len(valid_emission_cols) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Select top emission sources for clarity (top 10)\n",
    "    top_cols = df_emissions[valid_emission_cols].iloc[-1].nlargest(10).index.tolist()\n",
    "    \n",
    "    # Create stacked area chart\n",
    "    df_plot = df_emissions[top_cols]\n",
    "    \n",
    "    # Fill between for stacked effect\n",
    "    ax.stackplot(df_plot.index, \n",
    "                 df_plot.T, \n",
    "                 labels=[col.replace('emission_co2e_', '').replace('_', ' ').title()[:30] \n",
    "                        for col in top_cols],\n",
    "                 alpha=0.8)\n",
    "    \n",
    "    # Overlay total line\n",
    "    ax.plot(df_emissions.index, df_emissions['total_emissions'], \n",
    "            color='navy', linewidth=3, label='Total Emissions', linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Emissions (CO2e)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('GHG Emissions Pathways by Source', fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'C:\\Users\\shanp\\emissions_pathway.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Chart saved to: C:\\\\Users\\\\shanp\\\\emissions_pathway.png\")\n",
    "else:\n",
    "    print(\"Cannot create emissions chart - no valid data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4be682-14ea-46a6-b3ad-3c6d5abf79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 17: Create Scenario Comparison (Baseline vs Transformations)\n",
    "if 'df_transformed' in globals() and df_emissions is not None:\n",
    "    # Calculate emissions from transformed data\n",
    "    df_trans_emissions = df_transformed.groupby('time_period')[valid_emission_cols].sum()\n",
    "    df_trans_emissions['total_emissions'] = df_trans_emissions.sum(axis=1)\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('Scenario Comparison: Baseline vs Transformation', \n",
    "                 fontsize=18, fontweight='bold', y=1.02)\n",
    "    \n",
    "    # Plot 1: Total emissions comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.fill_between(df_emissions.index, 0, df_emissions['total_emissions'], \n",
    "                     alpha=0.5, label='Baseline', color='red')\n",
    "    ax1.fill_between(df_trans_emissions.index, 0, df_trans_emissions['total_emissions'], \n",
    "                     alpha=0.5, label='With Transformation', color='green')\n",
    "    ax1.set_title('Total Emissions', fontweight='bold')\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('CO2e')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Emissions reduction\n",
    "    ax2 = axes[0, 1]\n",
    "    reduction = df_emissions['total_emissions'] - df_trans_emissions['total_emissions']\n",
    "    ax2.bar(df_emissions.index, reduction, color='green', alpha=0.7)\n",
    "    ax2.set_title('Annual Emissions Reduction', fontweight='bold')\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('CO2e Reduced')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Cumulative reduction\n",
    "    ax3 = axes[1, 0]\n",
    "    cumulative_reduction = reduction.cumsum()\n",
    "    ax3.plot(df_emissions.index, cumulative_reduction, \n",
    "            color='darkgreen', linewidth=3, marker='o')\n",
    "    ax3.fill_between(df_emissions.index, 0, cumulative_reduction, alpha=0.3, color='green')\n",
    "    ax3.set_title('Cumulative Emissions Avoided', fontweight='bold')\n",
    "    ax3.set_xlabel('Year')\n",
    "    ax3.set_ylabel('Total CO2e Avoided')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Percentage reduction\n",
    "    ax4 = axes[1, 1]\n",
    "    pct_reduction = (reduction / df_emissions['total_emissions']) * 100\n",
    "    ax4.plot(df_emissions.index, pct_reduction, \n",
    "            color='darkblue', linewidth=3, marker='s')\n",
    "    ax4.set_title('Percentage Reduction', fontweight='bold')\n",
    "    ax4.set_xlabel('Year')\n",
    "    ax4.set_ylabel('% Reduction')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'C:\\Users\\shanp\\scenario_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Comparison chart saved\")\n",
    "    print(f\"Total emissions avoided: {cumulative_reduction.iloc[-1]:,.0f}\")\n",
    "    print(f\"Average annual reduction: {reduction.mean():,.0f}\")\n",
    "else:\n",
    "    print(\"Need df_transformed to create comparison. Run transformation first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab7ebc-eb15-418a-ac1d-9253ace05ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 18: Create Multi-Scenario Dashboard (Like Tableau Layout)\n",
    "def create_dashboard(df_baseline, df_scenarios, scenario_names):\n",
    "    \"\"\"\n",
    "    Create a Tableau-style dashboard with multiple scenarios\n",
    "    \"\"\"\n",
    "    n_scenarios = len(df_scenarios)\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Create grid\n",
    "    gs = fig.add_gridspec(3, n_scenarios + 1, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Title\n",
    "    fig.suptitle('GHG Emissions and Economic Pathways - Multi-Scenario Analysis', \n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Row 1: Emissions pathways for each scenario\n",
    "    for i, (df_scenario, name) in enumerate(zip(df_scenarios, scenario_names)):\n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        \n",
    "        # Calculate emissions\n",
    "        if valid_emission_cols:\n",
    "            emissions = df_scenario.groupby('time_period')[valid_emission_cols[:5]].sum()\n",
    "            ax.stackplot(emissions.index, emissions.T, alpha=0.7)\n",
    "            \n",
    "            # Add total line\n",
    "            total = emissions.sum(axis=1)\n",
    "            ax.plot(emissions.index, total, 'k-', linewidth=2, label='Total')\n",
    "            \n",
    "        ax.set_title(f'{name}\\nEmissions', fontweight='bold', fontsize=10)\n",
    "        ax.set_xlabel('Year', fontsize=8)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "    \n",
    "    # Row 2: GDP pathways\n",
    "    for i, (df_scenario, name) in enumerate(zip(df_scenarios, scenario_names)):\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "        \n",
    "        if gdp_cols:\n",
    "            gdp = df_scenario.groupby('time_period')[gdp_cols[:3]].sum()\n",
    "            for col in gdp.columns:\n",
    "                ax.plot(gdp.index, gdp[col], marker='o', markersize=3, linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'{name}\\nEconomic Output', fontweight='bold', fontsize=10)\n",
    "        ax.set_xlabel('Year', fontsize=8)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "    \n",
    "    # Row 3: Comparison metrics\n",
    "    ax_compare = fig.add_subplot(gs[2, :])\n",
    "    \n",
    "    # Calculate final year emissions for each scenario\n",
    "    final_emissions = []\n",
    "    for df_scenario in df_scenarios:\n",
    "        if valid_emission_cols:\n",
    "            final = df_scenario.groupby('time_period')[valid_emission_cols].sum().iloc[-1].sum()\n",
    "            final_emissions.append(final)\n",
    "    \n",
    "    if final_emissions:\n",
    "        x_pos = np.arange(len(scenario_names))\n",
    "        colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.7, len(scenario_names)))\n",
    "        bars = ax_compare.bar(x_pos, final_emissions, color=colors, alpha=0.8)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, final_emissions):\n",
    "            height = bar.get_height()\n",
    "            ax_compare.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                          f'{val:,.0f}',\n",
    "                          ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        ax_compare.set_xticks(x_pos)\n",
    "        ax_compare.set_xticklabels(scenario_names, rotation=45, ha='right')\n",
    "        ax_compare.set_title('Final Year (2050) Total Emissions Comparison', \n",
    "                           fontweight='bold', fontsize=12)\n",
    "        ax_compare.set_ylabel('Total CO2e', fontweight='bold')\n",
    "        ax_compare.grid(True, alpha=0.2, axis='y')\n",
    "    \n",
    "    plt.savefig(r'C:\\Users\\shanp\\multi_scenario_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Dashboard saved to: C:\\\\Users\\\\shanp\\\\multi_scenario_dashboard.png\")\n",
    "\n",
    "# Example usage (you need to create multiple scenarios first)\n",
    "print(\"Dashboard function defined. Use after creating multiple scenarios.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d84a4e-576f-4869-8433-fcdd338f3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 19: Run Multiple Transformations and Create Dashboard\n",
    "if transformers is not None:\n",
    "    print(\"Creating multiple transformation scenarios...\")\n",
    "    \n",
    "    # Select different transformers to compare\n",
    "    transformer_codes = [\n",
    "        \"TFR:ENTC:TARGET_RENEWABLE_ELEC\",\n",
    "        \"TFR:TRNS:SHIFT_FUEL_LIGHT_DUTY\",\n",
    "        \"TFR:AGRC:INC_PRODUCTIVITY\",\n",
    "        \"TFR:WASO:INC_RECYCLING\"\n",
    "    ]\n",
    "    \n",
    "    scenarios = [df_input]  # Baseline\n",
    "    scenario_names = [\"Baseline\"]\n",
    "    \n",
    "    for code in transformer_codes:\n",
    "        try:\n",
    "            transformer = transformers.get_transformer(code)\n",
    "            df_scenario = transformer()\n",
    "            scenarios.append(df_scenario)\n",
    "            \n",
    "            # Create readable name\n",
    "            name = code.split(':')[-1].replace('_', ' ').title()\n",
    "            scenario_names.append(name)\n",
    "            \n",
    "            print(f\"✓ Created scenario: {name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to create {code}: {str(e)[:100]}\")\n",
    "    \n",
    "    # Create dashboard\n",
    "    if len(scenarios) > 1:\n",
    "        create_dashboard(df_input, scenarios, scenario_names)\n",
    "    else:\n",
    "        print(\"Not enough scenarios created for dashboard\")\n",
    "else:\n",
    "    print(\"Transformers not available - load sisepuede first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0881604-f74d-43b4-a832-ff06de93c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 20: Export Results Summary\n",
    "# Create summary Excel file with multiple sheets\n",
    "output_excel = r\"C:\\Users\\shanp\\sisepuede_analysis_results.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "    # Sheet 1: Baseline emissions\n",
    "    if df_emissions is not None:\n",
    "        df_emissions.to_excel(writer, sheet_name='Baseline_Emissions')\n",
    "    \n",
    "    # Sheet 2: Transformed emissions (if available)\n",
    "    if 'df_trans_emissions' in globals():\n",
    "        df_trans_emissions.to_excel(writer, sheet_name='Transformed_Emissions')\n",
    "    \n",
    "    # Sheet 3: Summary statistics\n",
    "    summary_data = {\n",
    "        'Metric': ['Total Columns', 'Emission Columns', 'GDP Columns', \n",
    "                   'Time Periods', 'Regions'],\n",
    "        'Count': [len(df_input.columns), len(emission_cols) if emission_cols else 0,\n",
    "                 len(gdp_cols) if gdp_cols else 0,\n",
    "                 df_input['time_period'].nunique(),\n",
    "                 df_input['region'].nunique()]\n",
    "    }\n",
    "    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    print(f\"✓ Results exported to: {output_excel}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
